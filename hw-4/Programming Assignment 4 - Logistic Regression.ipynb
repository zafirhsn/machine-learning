{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 4 - Logistic Regression (170 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Important Libraries\n",
    "from sklearn.datasets import load_breast_cancer # taking included data set from Sklearn http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\n",
    "from sklearn.linear_model import LogisticRegression # importing Sklearn's logistic regression's module\n",
    "from sklearn import preprocessing # preprossing is what we do with the data before we run the learning algorithm\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Load the dataset - 5 points\n",
    "cancer = load_breast_cancer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Print the shape of data (X) and target (Y) values - 5 points\n",
    "print(cancer.target.shape)\n",
    "print(cancer.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "Scale before splitting the data into train and test- scale the data since we will be using gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Use preprocessing to scale the data and use train_test_split to split the data (70% train and 30% test) - 5 points\n",
    "x_scale = preprocessing.scale(cancer.data)\n",
    "y = cancer.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scale,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426,)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Print the shape of x_train and y_train - 5 points\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# Printing the names of all the features\n",
    "print(cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Logistic Regression Using Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the sigmoid function - 10 points\n",
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - Sigmoid of 0 should be equal to half\n",
    "print(sigmoid(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 31)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Append a column of ones to x_train - 10 points\n",
    "# ones is a vector of shape n,1\n",
    "ones = np.ones(x_train.shape[0]).reshape((x_train.shape[0], 1))\n",
    "# Append a column of ones in the beginning of x_train an save in variable a.\n",
    "a = np.hstack((ones, x_train))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Initialize Parameter Vector w: A vector of shape x_train.shape[1],1 - 5 points\n",
    "w = np.zeros((a.shape[1], 1))\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the hypothesis function - 10 points\n",
    "def hypothesis(a , w):\n",
    "    return sigmoid(np.matmul(a,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Compute y_hat using a and w - 5 points\n",
    "yhat = hypothesis(a, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Function.\n",
    "Write the code to calculate the log likelihood as discussed in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the log likelihood function - 15 points \n",
    "def likelihood(X_tr , Y_tr , w , n):\n",
    "    yhat = hypothesis(X_tr, w)\n",
    "    Y_tr = Y_tr.reshape((yhat.shape[0]), 1)\n",
    "    likelihood = np.sum(Y_tr * np.log(yhat) + (1 - Y_tr) * np.log(1 - yhat))\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-295.2806989185367\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - The value should be equal to -295.2806989185367.\n",
    "print(likelihood(a,y_train,w,a.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO - Write the gradient ascent function - 25 points\n",
    "def Gradient_Ascent(a, y, learning_rate, num_iters):\n",
    "    n = None # Number of training examples.\n",
    "    # TODO - Initialize w. Zeros vector of shape x_train.shape[1],1\n",
    "    w = None\n",
    "    # TODO - Reshape y to be a rank 2 matrix.\n",
    "    y = None\n",
    "    # TODO - Initiating list to store values of likelihood after few iterations.\n",
    "    likelihood_values = []\n",
    "    for i in range(num_iters):\n",
    "        yhat = None\n",
    "        error = None\n",
    "        gradient = None\n",
    "        # Updating Parameters\n",
    "        w = None\n",
    "        if (i % 100) == 0:\n",
    "            likelihood_values.append(likelihood(a,y,w,n))\n",
    "        \n",
    "    return w, likelihood_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujjwalsinghania/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n",
      "/Users/ujjwalsinghania/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.22144977]\n",
      " [  5.40230165]\n",
      " [ -1.29691362]\n",
      " [  5.48873026]\n",
      " [ -0.19503516]\n",
      " [ -2.03687402]\n",
      " [ 12.24001414]\n",
      " [ -8.94148557]\n",
      " [ -7.93523054]\n",
      " [  4.00972654]\n",
      " [ -5.58061483]\n",
      " [-13.69400184]\n",
      " [  2.96079775]\n",
      " [  5.26888015]\n",
      " [-13.64988283]\n",
      " [  1.05085696]\n",
      " [ -4.51494167]\n",
      " [  5.0851475 ]\n",
      " [ -9.331508  ]\n",
      " [  5.66281395]\n",
      " [  9.25341835]\n",
      " [ -5.21545132]\n",
      " [ -7.28979615]\n",
      " [  0.16343147]\n",
      " [-13.99543156]\n",
      " [  1.55870384]\n",
      " [  6.61675198]\n",
      " [-11.13473703]\n",
      " [ -0.0448658 ]\n",
      " [-10.39257167]\n",
      " [ -0.49036323]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = None\n",
    "num_iters = None\n",
    "w, likelihood_values = None\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Likelihood v/s Number of Iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKyUKERHJ6v8DRo+LhQXeaZYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1047c6b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to plot Likelihood v/s Number of Iterations.\n",
    "iters = np.array(range(0,num_iters,100))\n",
    "plt.plot(iters,likelihood_values,'.-',color='green')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.title(\"Likelihood vs Number of Iterations.\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the likelihood increasing as number of Iterations increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO - Write the function to compute predicted values using a and w - 10 points\n",
    "def predict(a, w):\n",
    "    yhat = None\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+000]\n",
      " [9.71497110e-025]\n",
      " [1.00000000e+000]\n",
      " [9.94686167e-001]\n",
      " [9.99993990e-001]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [3.62539177e-001]\n",
      " [9.99999768e-001]\n",
      " [7.13169757e-017]\n",
      " [1.66707191e-017]\n",
      " [2.05400203e-028]\n",
      " [9.99844533e-001]\n",
      " [9.99063601e-001]\n",
      " [1.66214747e-001]\n",
      " [6.19930994e-028]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [7.31985396e-012]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.99999506e-001]\n",
      " [1.00000000e+000]\n",
      " [7.00444394e-019]\n",
      " [9.99999998e-001]\n",
      " [1.00000000e+000]\n",
      " [1.16324120e-008]\n",
      " [1.00000000e+000]\n",
      " [1.93698455e-058]\n",
      " [9.99999996e-001]\n",
      " [9.86332308e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99876394e-001]\n",
      " [9.99999996e-001]\n",
      " [1.55189800e-001]\n",
      " [9.99999865e-001]\n",
      " [7.63442230e-027]\n",
      " [9.99999876e-001]\n",
      " [9.99999998e-001]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [7.42145047e-024]\n",
      " [1.88292025e-016]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.49150997e-035]\n",
      " [1.93471423e-027]\n",
      " [1.86903271e-030]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.05044653e-018]\n",
      " [1.00000000e+000]\n",
      " [9.99999999e-001]\n",
      " [9.99999997e-001]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.85727553e-001]\n",
      " [9.99999999e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99999999e-001]\n",
      " [9.99999767e-001]\n",
      " [4.31757944e-025]\n",
      " [1.00000000e+000]\n",
      " [3.37953692e-016]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.96390058e-001]\n",
      " [8.77278967e-001]\n",
      " [9.80430967e-001]\n",
      " [1.72723641e-013]\n",
      " [9.99989985e-001]\n",
      " [9.98747033e-001]\n",
      " [9.99999998e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99330963e-001]\n",
      " [1.83436095e-010]\n",
      " [9.98250719e-001]\n",
      " [9.09748691e-001]\n",
      " [6.82833974e-005]\n",
      " [5.93789170e-011]\n",
      " [1.00000000e+000]\n",
      " [9.99999998e-001]\n",
      " [2.03234091e-006]\n",
      " [9.66400980e-001]\n",
      " [2.19056574e-021]\n",
      " [5.01685001e-027]\n",
      " [1.51066621e-041]\n",
      " [9.99861822e-001]\n",
      " [9.99999055e-001]\n",
      " [1.00000000e+000]\n",
      " [1.86815161e-016]\n",
      " [1.00000000e+000]\n",
      " [9.99999434e-001]\n",
      " [9.99991831e-001]\n",
      " [3.47253483e-029]\n",
      " [9.99999686e-001]\n",
      " [9.99445753e-001]\n",
      " [7.36017836e-037]\n",
      " [9.99999981e-001]\n",
      " [1.26158009e-054]\n",
      " [1.76961960e-043]\n",
      " [7.85477530e-001]\n",
      " [1.78366107e-023]\n",
      " [9.99999999e-001]\n",
      " [2.87622166e-016]\n",
      " [9.50206606e-001]\n",
      " [9.99999988e-001]\n",
      " [9.64671184e-001]\n",
      " [1.11323243e-037]\n",
      " [8.99315607e-061]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.47673148e-043]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.45778378e-001]\n",
      " [9.99999884e-001]\n",
      " [1.28195876e-045]\n",
      " [9.99999949e-001]\n",
      " [8.88985074e-017]\n",
      " [1.00000000e+000]\n",
      " [9.99997044e-001]\n",
      " [3.35147161e-015]\n",
      " [9.99991325e-001]\n",
      " [2.95907588e-057]\n",
      " [1.00000000e+000]\n",
      " [9.99975848e-001]\n",
      " [1.78123413e-015]\n",
      " [2.28356093e-003]\n",
      " [1.00000000e+000]\n",
      " [5.18540007e-002]\n",
      " [9.99999988e-001]\n",
      " [5.78601040e-045]\n",
      " [5.80134775e-046]\n",
      " [9.91295579e-001]\n",
      " [1.00000000e+000]\n",
      " [1.52835964e-014]\n",
      " [1.00000000e+000]\n",
      " [2.58457808e-009]\n",
      " [9.99999982e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99999988e-001]\n",
      " [7.75957311e-009]\n",
      " [9.78669271e-008]\n",
      " [1.00000000e+000]\n",
      " [2.44225520e-028]\n",
      " [1.14729055e-034]\n",
      " [9.99990157e-001]\n",
      " [8.75767211e-022]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.99561773e-001]\n",
      " [9.51047294e-001]\n",
      " [9.99999993e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99999998e-001]\n",
      " [1.00000000e+000]\n",
      " [4.76733390e-019]\n",
      " [3.72695851e-006]\n",
      " [1.44508118e-001]\n",
      " [7.27207474e-033]\n",
      " [1.48018308e-022]\n",
      " [4.27156494e-012]\n",
      " [8.81047237e-001]\n",
      " [9.99999906e-001]\n",
      " [1.00000000e+000]\n",
      " [1.45644588e-010]\n",
      " [9.99999999e-001]\n",
      " [1.00000000e+000]\n",
      " [1.71146708e-006]\n",
      " [9.96530332e-001]\n",
      " [1.00000000e+000]\n",
      " [5.36829447e-021]\n",
      " [7.55329857e-076]\n",
      " [5.76926260e-005]\n",
      " [9.99999999e-001]\n",
      " [1.00000000e+000]\n",
      " [7.22870810e-001]\n",
      " [4.22153472e-030]\n",
      " [1.82871445e-009]\n",
      " [9.99897169e-001]\n",
      " [9.99999999e-001]\n",
      " [7.89370372e-014]\n",
      " [6.07764429e-010]\n",
      " [9.99998911e-001]\n",
      " [2.67660999e-022]\n",
      " [1.43063852e-007]\n",
      " [5.64300996e-012]\n",
      " [5.16497817e-004]\n",
      " [9.32838409e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99999832e-001]\n",
      " [9.99999582e-001]\n",
      " [1.00000000e+000]\n",
      " [9.11802287e-001]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.65720315e-026]\n",
      " [1.00000000e+000]\n",
      " [1.95989029e-061]\n",
      " [9.99990616e-001]\n",
      " [9.99999998e-001]\n",
      " [1.00528580e-014]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.90792734e-001]\n",
      " [2.18686032e-017]\n",
      " [9.99275628e-001]\n",
      " [1.87186079e-016]\n",
      " [9.99999999e-001]\n",
      " [7.87011707e-002]\n",
      " [5.74092764e-131]\n",
      " [1.00000000e+000]\n",
      " [5.91383370e-073]\n",
      " [3.75974715e-025]\n",
      " [1.00000000e+000]\n",
      " [5.84796295e-003]\n",
      " [3.85065804e-019]\n",
      " [9.99999993e-001]\n",
      " [7.67766848e-012]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.28716491e-012]\n",
      " [8.85112515e-044]\n",
      " [9.99409148e-001]\n",
      " [8.24562361e-008]\n",
      " [1.00000000e+000]\n",
      " [7.21350275e-023]\n",
      " [9.99999998e-001]\n",
      " [3.16205610e-021]\n",
      " [1.00000000e+000]\n",
      " [7.94952201e-001]\n",
      " [2.72621846e-027]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [6.47086576e-016]\n",
      " [9.99860007e-001]\n",
      " [1.53015679e-007]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [7.12555944e-024]\n",
      " [1.00000000e+000]\n",
      " [6.51079302e-042]\n",
      " [9.99999127e-001]\n",
      " [2.05135959e-014]\n",
      " [1.12555433e-012]\n",
      " [4.91010997e-027]\n",
      " [9.99999970e-001]\n",
      " [9.99999996e-001]\n",
      " [9.99999994e-001]\n",
      " [3.13298277e-018]\n",
      " [9.99999999e-001]\n",
      " [7.49749360e-016]\n",
      " [9.99999999e-001]\n",
      " [2.38426949e-018]\n",
      " [9.99999994e-001]\n",
      " [2.01794274e-032]\n",
      " [6.09084833e-003]\n",
      " [9.99999974e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99999797e-001]\n",
      " [8.57164102e-001]\n",
      " [9.07464463e-007]\n",
      " [9.99634340e-001]\n",
      " [9.69607460e-024]\n",
      " [1.00000000e+000]\n",
      " [1.59909083e-032]\n",
      " [9.99999989e-001]\n",
      " [9.59617779e-005]\n",
      " [9.99999882e-001]\n",
      " [1.80388587e-009]\n",
      " [9.99999987e-001]\n",
      " [9.99999998e-001]\n",
      " [4.02889989e-049]\n",
      " [2.37274463e-004]\n",
      " [1.01306733e-031]\n",
      " [9.99999998e-001]\n",
      " [9.99827743e-001]\n",
      " [1.00064409e-014]\n",
      " [5.48566955e-002]\n",
      " [9.56804849e-001]\n",
      " [9.67063500e-001]\n",
      " [5.24597521e-013]\n",
      " [2.60756194e-007]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.99999908e-001]\n",
      " [9.99999960e-001]\n",
      " [9.83152223e-002]\n",
      " [4.42891151e-007]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.99999999e-001]\n",
      " [9.99934275e-001]\n",
      " [8.47808068e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99999108e-001]\n",
      " [1.00000000e+000]\n",
      " [3.78772324e-031]\n",
      " [7.77849328e-009]\n",
      " [9.99897848e-001]\n",
      " [9.99999999e-001]\n",
      " [1.00000000e+000]\n",
      " [1.25290471e-037]\n",
      " [3.42406207e-001]\n",
      " [9.99999820e-001]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.99977661e-001]\n",
      " [5.25086106e-001]\n",
      " [1.15816306e-015]\n",
      " [9.99999885e-001]\n",
      " [8.18731373e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99569640e-001]\n",
      " [5.49679930e-014]\n",
      " [5.81806173e-001]\n",
      " [7.78990288e-027]\n",
      " [9.99971803e-001]\n",
      " [1.00000000e+000]\n",
      " [9.51339654e-001]\n",
      " [2.88217787e-031]\n",
      " [8.78479222e-001]\n",
      " [5.57308660e-010]\n",
      " [1.00000000e+000]\n",
      " [9.99999515e-001]\n",
      " [6.44193321e-019]\n",
      " [9.99999997e-001]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.99999999e-001]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.42653244e-024]\n",
      " [2.26879142e-033]\n",
      " [5.80413782e-005]\n",
      " [4.11019938e-047]\n",
      " [1.55083422e-025]\n",
      " [9.99984065e-001]\n",
      " [9.99999995e-001]\n",
      " [2.85247932e-039]\n",
      " [7.48909025e-001]\n",
      " [9.99999991e-001]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [9.77674922e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99999968e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99999434e-001]\n",
      " [9.99999996e-001]\n",
      " [2.76864128e-002]\n",
      " [9.99999997e-001]\n",
      " [2.60227676e-028]\n",
      " [8.34615255e-046]\n",
      " [9.99991006e-001]\n",
      " [9.99979384e-001]\n",
      " [2.75739527e-006]\n",
      " [9.99999997e-001]\n",
      " [9.99999984e-001]\n",
      " [9.99387802e-001]\n",
      " [9.97425773e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99974256e-001]\n",
      " [7.10328141e-001]\n",
      " [9.93418073e-001]\n",
      " [2.63453222e-023]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [5.55818537e-022]\n",
      " [1.00000000e+000]\n",
      " [1.00000000e+000]\n",
      " [1.23404191e-038]\n",
      " [1.73829024e-004]\n",
      " [2.56093009e-029]\n",
      " [8.77510075e-017]\n",
      " [1.72498297e-007]\n",
      " [9.99990511e-001]\n",
      " [2.14194819e-015]\n",
      " [9.99998464e-001]\n",
      " [9.99999993e-001]\n",
      " [8.32071963e-001]\n",
      " [2.33598932e-020]\n",
      " [9.99999879e-001]\n",
      " [9.99875886e-001]\n",
      " [1.00000000e+000]\n",
      " [2.94274910e-018]\n",
      " [1.00000000e+000]\n",
      " [3.24439887e-032]\n",
      " [8.17821832e-040]\n",
      " [7.16188552e-037]\n",
      " [4.58714826e-007]\n",
      " [2.28790148e-010]\n",
      " [3.91295015e-015]\n",
      " [2.74659515e-045]\n",
      " [4.23213345e-016]\n",
      " [9.99999988e-001]\n",
      " [9.93223825e-001]\n",
      " [2.80772660e-018]\n",
      " [3.75602931e-001]\n",
      " [3.56977802e-022]\n",
      " [2.01639529e-007]\n",
      " [9.99996619e-001]\n",
      " [9.99989572e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99999855e-001]\n",
      " [9.99999999e-001]\n",
      " [9.99999884e-001]\n",
      " [1.00000000e+000]\n",
      " [9.99972293e-001]\n",
      " [6.62775293e-027]\n",
      " [2.92530711e-025]\n",
      " [9.99448226e-001]\n",
      " [9.99999999e-001]]\n"
     ]
    }
   ],
   "source": [
    "yhat = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO - Write the precision_recall function - 20 points\n",
    "def precision_recall(yhat, y , threshold):\n",
    "    # Write code to compute precision and recall\n",
    "    # Before finding precision or recall, you have to convert yhat into a vector of zeros and ones using threshold.\n",
    "    # Values in yhat > threshold should be equal to 1 and others should be 0.\n",
    "    \n",
    "    precision = None\n",
    "    recall = None\n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9886363636363636\n",
      "0.9961832061068703\n"
     ]
    }
   ],
   "source": [
    "precision, recall = None\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9923954372623575\n"
     ]
    }
   ],
   "source": [
    "# TODO - Write the f_score function - 10 points\n",
    "def f_score(precision, recall):\n",
    "    return None\n",
    "\n",
    "print(f_score(precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Model using Sk Learn Library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO - Create object of logistic regression model. Pass a large value of C (C = 1/lambda) to make lambda nearly 0. - 5 points\n",
    "logreg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000000, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - Fit the model - 5 points\n",
    "# Don't use matrix a. Instead, use x_train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 1.000000\n"
     ]
    }
   ],
   "source": [
    "# TODO - Find the predicted values on training set using logreg.predict - 5 points\n",
    "yhat = None\n",
    "# TODO - Find the accuracy achieved on training set using logreg.score - 5 points\n",
    "acc = None\n",
    "\n",
    "print(\"Accuracy on training data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.47984117e+01 -2.06543943e+01  3.12770800e+01 -2.13787045e+00\n",
      "   7.97953361e-01  1.28587045e+02 -1.93304284e+02 -8.09336079e+00\n",
      "   1.96161431e+01 -4.25980723e+01 -1.39242038e+02  5.47193686e+00\n",
      "   1.49913326e+02 -1.51486173e+02  1.07235287e+01 -6.53898078e+01\n",
      "   9.99398121e+01 -5.93914742e+01  2.77478290e+01  6.82998775e+01\n",
      "   3.47505473e+00 -1.84201111e+01 -1.45342768e+02 -7.74089833e+01\n",
      "  -1.45390914e-01  5.21929196e+01 -2.01309302e+01 -7.24649902e+01\n",
      "  -3.69090923e+01 -2.86230768e+01]]\n",
      "[-61.04913322]\n"
     ]
    }
   ],
   "source": [
    "# TODO - Print out all the coefficients - 5 points\n",
    "w = None\n",
    "intercept = None\n",
    "# VERIFY - Compare the parameters computed by logreg model and gradient ascent. They should be nearly same.\n",
    "print(w)\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n",
      "[1. 1.]\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# TODO - Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn - 5 points\n",
    "prec , recal , fscore,_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the values of precision, recall and fscore using the methods you wrote and using sklearn method.\n",
    "To match the values of precision, recall and fscore using both methods, you will have to try different values of threshold in your method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
