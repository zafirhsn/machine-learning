{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2 - Multiple Linear Regression (80 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Multiple Linear Regression Using Gradient Descent And Stochastic Gradient Descent Algorithm.\n",
    "\n",
    "In this assignment, you will be implementing Multiple Linear Regression Model on the same data set as in Programming Assignment 1, but here we will be using gradient descent algorithm (GDA) and stochastic gradient descent algorithm (SGDA) to minimize the cost function as taught in the class. The SGDA implementation is optional.\n",
    "\n",
    "Please add your own print statements to check your code to ensure your code is correct in every step.  (Note: we will not be grading the print statements you add to your code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code cell using Shift + Enter before moving further\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data set.\n",
    "\n",
    "In the below code cell, you will load the data using python pandas library as done in the programming_assignment_1b. Use pd.read_csv('File url ', header=None,.... ) with the value of header=None,delim_whitespace=True,names=names,na_values='?' as attributes. The url for the .data file is https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data. This step is same as done in programming_assignment_1b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
      "0     0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296.0   \n",
      "1     0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242.0   \n",
      "2     0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242.0   \n",
      "3     0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222.0   \n",
      "4     0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222.0   \n",
      "5     0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222.0   \n",
      "6     0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311.0   \n",
      "7     0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311.0   \n",
      "8     0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311.0   \n",
      "9     0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311.0   \n",
      "10    0.22489  12.5   7.87     0  0.524  6.377   94.3  6.3467    5  311.0   \n",
      "11    0.11747  12.5   7.87     0  0.524  6.009   82.9  6.2267    5  311.0   \n",
      "12    0.09378  12.5   7.87     0  0.524  5.889   39.0  5.4509    5  311.0   \n",
      "13    0.62976   0.0   8.14     0  0.538  5.949   61.8  4.7075    4  307.0   \n",
      "14    0.63796   0.0   8.14     0  0.538  6.096   84.5  4.4619    4  307.0   \n",
      "15    0.62739   0.0   8.14     0  0.538  5.834   56.5  4.4986    4  307.0   \n",
      "16    1.05393   0.0   8.14     0  0.538  5.935   29.3  4.4986    4  307.0   \n",
      "17    0.78420   0.0   8.14     0  0.538  5.990   81.7  4.2579    4  307.0   \n",
      "18    0.80271   0.0   8.14     0  0.538  5.456   36.6  3.7965    4  307.0   \n",
      "19    0.72580   0.0   8.14     0  0.538  5.727   69.5  3.7965    4  307.0   \n",
      "20    1.25179   0.0   8.14     0  0.538  5.570   98.1  3.7979    4  307.0   \n",
      "21    0.85204   0.0   8.14     0  0.538  5.965   89.2  4.0123    4  307.0   \n",
      "22    1.23247   0.0   8.14     0  0.538  6.142   91.7  3.9769    4  307.0   \n",
      "23    0.98843   0.0   8.14     0  0.538  5.813  100.0  4.0952    4  307.0   \n",
      "24    0.75026   0.0   8.14     0  0.538  5.924   94.1  4.3996    4  307.0   \n",
      "25    0.84054   0.0   8.14     0  0.538  5.599   85.7  4.4546    4  307.0   \n",
      "26    0.67191   0.0   8.14     0  0.538  5.813   90.3  4.6820    4  307.0   \n",
      "27    0.95577   0.0   8.14     0  0.538  6.047   88.8  4.4534    4  307.0   \n",
      "28    0.77299   0.0   8.14     0  0.538  6.495   94.4  4.4547    4  307.0   \n",
      "29    1.00245   0.0   8.14     0  0.538  6.674   87.3  4.2390    4  307.0   \n",
      "..        ...   ...    ...   ...    ...    ...    ...     ...  ...    ...   \n",
      "476   4.87141   0.0  18.10     0  0.614  6.484   93.6  2.3053   24  666.0   \n",
      "477  15.02340   0.0  18.10     0  0.614  5.304   97.3  2.1007   24  666.0   \n",
      "478  10.23300   0.0  18.10     0  0.614  6.185   96.7  2.1705   24  666.0   \n",
      "479  14.33370   0.0  18.10     0  0.614  6.229   88.0  1.9512   24  666.0   \n",
      "480   5.82401   0.0  18.10     0  0.532  6.242   64.7  3.4242   24  666.0   \n",
      "481   5.70818   0.0  18.10     0  0.532  6.750   74.9  3.3317   24  666.0   \n",
      "482   5.73116   0.0  18.10     0  0.532  7.061   77.0  3.4106   24  666.0   \n",
      "483   2.81838   0.0  18.10     0  0.532  5.762   40.3  4.0983   24  666.0   \n",
      "484   2.37857   0.0  18.10     0  0.583  5.871   41.9  3.7240   24  666.0   \n",
      "485   3.67367   0.0  18.10     0  0.583  6.312   51.9  3.9917   24  666.0   \n",
      "486   5.69175   0.0  18.10     0  0.583  6.114   79.8  3.5459   24  666.0   \n",
      "487   4.83567   0.0  18.10     0  0.583  5.905   53.2  3.1523   24  666.0   \n",
      "488   0.15086   0.0  27.74     0  0.609  5.454   92.7  1.8209    4  711.0   \n",
      "489   0.18337   0.0  27.74     0  0.609  5.414   98.3  1.7554    4  711.0   \n",
      "490   0.20746   0.0  27.74     0  0.609  5.093   98.0  1.8226    4  711.0   \n",
      "491   0.10574   0.0  27.74     0  0.609  5.983   98.8  1.8681    4  711.0   \n",
      "492   0.11132   0.0  27.74     0  0.609  5.983   83.5  2.1099    4  711.0   \n",
      "493   0.17331   0.0   9.69     0  0.585  5.707   54.0  2.3817    6  391.0   \n",
      "494   0.27957   0.0   9.69     0  0.585  5.926   42.6  2.3817    6  391.0   \n",
      "495   0.17899   0.0   9.69     0  0.585  5.670   28.8  2.7986    6  391.0   \n",
      "496   0.28960   0.0   9.69     0  0.585  5.390   72.9  2.7986    6  391.0   \n",
      "497   0.26838   0.0   9.69     0  0.585  5.794   70.6  2.8927    6  391.0   \n",
      "498   0.23912   0.0   9.69     0  0.585  6.019   65.3  2.4091    6  391.0   \n",
      "499   0.17783   0.0   9.69     0  0.585  5.569   73.5  2.3999    6  391.0   \n",
      "500   0.22438   0.0   9.69     0  0.585  6.027   79.7  2.4982    6  391.0   \n",
      "501   0.06263   0.0  11.93     0  0.573  6.593   69.1  2.4786    1  273.0   \n",
      "502   0.04527   0.0  11.93     0  0.573  6.120   76.7  2.2875    1  273.0   \n",
      "503   0.06076   0.0  11.93     0  0.573  6.976   91.0  2.1675    1  273.0   \n",
      "504   0.10959   0.0  11.93     0  0.573  6.794   89.3  2.3889    1  273.0   \n",
      "505   0.04741   0.0  11.93     0  0.573  6.030   80.8  2.5050    1  273.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  PRICE  \n",
      "0       15.3  396.90   4.98   24.0  \n",
      "1       17.8  396.90   9.14   21.6  \n",
      "2       17.8  392.83   4.03   34.7  \n",
      "3       18.7  394.63   2.94   33.4  \n",
      "4       18.7  396.90   5.33   36.2  \n",
      "5       18.7  394.12   5.21   28.7  \n",
      "6       15.2  395.60  12.43   22.9  \n",
      "7       15.2  396.90  19.15   27.1  \n",
      "8       15.2  386.63  29.93   16.5  \n",
      "9       15.2  386.71  17.10   18.9  \n",
      "10      15.2  392.52  20.45   15.0  \n",
      "11      15.2  396.90  13.27   18.9  \n",
      "12      15.2  390.50  15.71   21.7  \n",
      "13      21.0  396.90   8.26   20.4  \n",
      "14      21.0  380.02  10.26   18.2  \n",
      "15      21.0  395.62   8.47   19.9  \n",
      "16      21.0  386.85   6.58   23.1  \n",
      "17      21.0  386.75  14.67   17.5  \n",
      "18      21.0  288.99  11.69   20.2  \n",
      "19      21.0  390.95  11.28   18.2  \n",
      "20      21.0  376.57  21.02   13.6  \n",
      "21      21.0  392.53  13.83   19.6  \n",
      "22      21.0  396.90  18.72   15.2  \n",
      "23      21.0  394.54  19.88   14.5  \n",
      "24      21.0  394.33  16.30   15.6  \n",
      "25      21.0  303.42  16.51   13.9  \n",
      "26      21.0  376.88  14.81   16.6  \n",
      "27      21.0  306.38  17.28   14.8  \n",
      "28      21.0  387.94  12.80   18.4  \n",
      "29      21.0  380.23  11.98   21.0  \n",
      "..       ...     ...    ...    ...  \n",
      "476     20.2  396.21  18.68   16.7  \n",
      "477     20.2  349.48  24.91   12.0  \n",
      "478     20.2  379.70  18.03   14.6  \n",
      "479     20.2  383.32  13.11   21.4  \n",
      "480     20.2  396.90  10.74   23.0  \n",
      "481     20.2  393.07   7.74   23.7  \n",
      "482     20.2  395.28   7.01   25.0  \n",
      "483     20.2  392.92  10.42   21.8  \n",
      "484     20.2  370.73  13.34   20.6  \n",
      "485     20.2  388.62  10.58   21.2  \n",
      "486     20.2  392.68  14.98   19.1  \n",
      "487     20.2  388.22  11.45   20.6  \n",
      "488     20.1  395.09  18.06   15.2  \n",
      "489     20.1  344.05  23.97    7.0  \n",
      "490     20.1  318.43  29.68    8.1  \n",
      "491     20.1  390.11  18.07   13.6  \n",
      "492     20.1  396.90  13.35   20.1  \n",
      "493     19.2  396.90  12.01   21.8  \n",
      "494     19.2  396.90  13.59   24.5  \n",
      "495     19.2  393.29  17.60   23.1  \n",
      "496     19.2  396.90  21.14   19.7  \n",
      "497     19.2  396.90  14.10   18.3  \n",
      "498     19.2  396.90  12.92   21.2  \n",
      "499     19.2  395.77  15.10   17.5  \n",
      "500     19.2  396.90  14.33   16.8  \n",
      "501     21.0  391.99   9.67   22.4  \n",
      "502     21.0  396.90   9.08   20.6  \n",
      "503     21.0  396.90   5.64   23.9  \n",
      "504     21.0  393.45   6.48   22.0  \n",
      "505     21.0  396.90   7.88   11.9  \n",
      "\n",
      "[506 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# After completing the code in this code cell, run this code cell before moving further.\n",
    "names =[\n",
    "    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', \n",
    "    'AGE',  'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'PRICE'\n",
    "]\n",
    "\n",
    "# TODO - write the pandas command to read the csv file into a dataframe df - 5 points\n",
    "df= pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\", sep=\"\\s+\", names=names)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of taking just 1 feature i.e 'RM' as we did in Simple Linear Regression, we will use 4 features which are 'LSTAT', 'DIS', 'RM' and 'INDUS'. We choose only these features because they are almost on similar scale. So, there is no need for feature scaling. Fetching the values of 5 columns into a smaller dataframe (say) df1 from df. This step is also same as done in programming_assignment_1b.There we fetched only 2 columns but here we need 5 columns.We need the values in the 'PRICE', 'LSTAT', 'DIS', 'RM' and 'INDUS' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 5)\n",
      "     PRICE  LSTAT     DIS     RM  INDUS\n",
      "0     24.0   4.98  4.0900  6.575   2.31\n",
      "1     21.6   9.14  4.9671  6.421   7.07\n",
      "2     34.7   4.03  4.9671  7.185   7.07\n",
      "3     33.4   2.94  6.0622  6.998   2.18\n",
      "4     36.2   5.33  6.0622  7.147   2.18\n",
      "5     28.7   5.21  6.0622  6.430   2.18\n",
      "6     22.9  12.43  5.5605  6.012   7.87\n",
      "7     27.1  19.15  5.9505  6.172   7.87\n",
      "8     16.5  29.93  6.0821  5.631   7.87\n",
      "9     18.9  17.10  6.5921  6.004   7.87\n",
      "10    15.0  20.45  6.3467  6.377   7.87\n",
      "11    18.9  13.27  6.2267  6.009   7.87\n",
      "12    21.7  15.71  5.4509  5.889   7.87\n",
      "13    20.4   8.26  4.7075  5.949   8.14\n",
      "14    18.2  10.26  4.4619  6.096   8.14\n",
      "15    19.9   8.47  4.4986  5.834   8.14\n",
      "16    23.1   6.58  4.4986  5.935   8.14\n",
      "17    17.5  14.67  4.2579  5.990   8.14\n",
      "18    20.2  11.69  3.7965  5.456   8.14\n",
      "19    18.2  11.28  3.7965  5.727   8.14\n",
      "20    13.6  21.02  3.7979  5.570   8.14\n",
      "21    19.6  13.83  4.0123  5.965   8.14\n",
      "22    15.2  18.72  3.9769  6.142   8.14\n",
      "23    14.5  19.88  4.0952  5.813   8.14\n",
      "24    15.6  16.30  4.3996  5.924   8.14\n",
      "25    13.9  16.51  4.4546  5.599   8.14\n",
      "26    16.6  14.81  4.6820  5.813   8.14\n",
      "27    14.8  17.28  4.4534  6.047   8.14\n",
      "28    18.4  12.80  4.4547  6.495   8.14\n",
      "29    21.0  11.98  4.2390  6.674   8.14\n",
      "..     ...    ...     ...    ...    ...\n",
      "476   16.7  18.68  2.3053  6.484  18.10\n",
      "477   12.0  24.91  2.1007  5.304  18.10\n",
      "478   14.6  18.03  2.1705  6.185  18.10\n",
      "479   21.4  13.11  1.9512  6.229  18.10\n",
      "480   23.0  10.74  3.4242  6.242  18.10\n",
      "481   23.7   7.74  3.3317  6.750  18.10\n",
      "482   25.0   7.01  3.4106  7.061  18.10\n",
      "483   21.8  10.42  4.0983  5.762  18.10\n",
      "484   20.6  13.34  3.7240  5.871  18.10\n",
      "485   21.2  10.58  3.9917  6.312  18.10\n",
      "486   19.1  14.98  3.5459  6.114  18.10\n",
      "487   20.6  11.45  3.1523  5.905  18.10\n",
      "488   15.2  18.06  1.8209  5.454  27.74\n",
      "489    7.0  23.97  1.7554  5.414  27.74\n",
      "490    8.1  29.68  1.8226  5.093  27.74\n",
      "491   13.6  18.07  1.8681  5.983  27.74\n",
      "492   20.1  13.35  2.1099  5.983  27.74\n",
      "493   21.8  12.01  2.3817  5.707   9.69\n",
      "494   24.5  13.59  2.3817  5.926   9.69\n",
      "495   23.1  17.60  2.7986  5.670   9.69\n",
      "496   19.7  21.14  2.7986  5.390   9.69\n",
      "497   18.3  14.10  2.8927  5.794   9.69\n",
      "498   21.2  12.92  2.4091  6.019   9.69\n",
      "499   17.5  15.10  2.3999  5.569   9.69\n",
      "500   16.8  14.33  2.4982  6.027   9.69\n",
      "501   22.4   9.67  2.4786  6.593  11.93\n",
      "502   20.6   9.08  2.2875  6.120  11.93\n",
      "503   23.9   5.64  2.1675  6.976  11.93\n",
      "504   22.0   6.48  2.3889  6.794  11.93\n",
      "505   11.9   7.88  2.5050  6.030  11.93\n",
      "\n",
      "[506 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO - Save values from columns 'PRICE', 'LSTAT', 'DIS', 'RM', 'INDUS' into df1 from df - 5 points\n",
    "df1= df[[\"PRICE\", \"LSTAT\", \"DIS\", \"RM\", \"INDUS\"]]\n",
    "\n",
    "# TODO - Remove nan values from df1 and save into df2 - 5 points\n",
    "df2= df1[~np.isnan(df1)]\n",
    "\n",
    "# Check the shape of df2. It should be (506,5)\n",
    "print(df2.shape)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 4)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Create a vector y having the values of 'PRICE' column and matrix x having the values of\n",
    "# LSTAT', 'DIS', 'RM' and 'INDUS' columns - 5 points\n",
    "y = np.array(df2[\"PRICE\"])\n",
    "x = df2[[\"LSTAT\", \"DIS\", \"RM\", \"INDUS\"]]\n",
    "x = x.values\n",
    "# Check the shape of x and y vectors.\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape y to be rank 2. After checking the shape of x and y in the above code cell, we see that x is already rank 2 and y are rank 1 matrix. Before moving ahead, convert y to be rank 2 matrix. For example, I would use the command y=y.reshape(y.shape[0],1) to reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 1)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Reshape y into a rank 2 matrix - 5 points\n",
    "y = y.reshape(y.shape[0], 1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the value of n i.e. number of training examples. \n",
    "Hint: Value of n is equal to the number of rows in either x or y matrix which can be accessed using numpy shape command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n"
     ]
    }
   ],
   "source": [
    "# TODO - Save number of training examples into n and print it - 5 points\n",
    "n = y.shape[0]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.      4.98    4.09    6.575   2.31  ]\n",
      " [ 1.      9.14    4.9671  6.421   7.07  ]\n",
      " [ 1.      4.03    4.9671  7.185   7.07  ]\n",
      " ...\n",
      " [ 1.      5.64    2.1675  6.976  11.93  ]\n",
      " [ 1.      6.48    2.3889  6.794  11.93  ]\n",
      " [ 1.      7.88    2.505   6.03   11.93  ]]\n",
      "(506, 5)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Append a column of ones in x. Use hstack - 5 points\n",
    "\n",
    "x = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "print(x)\n",
    "\n",
    "# Shape of x should be (506,5)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function.\n",
    "Compute the cost: Write the code to compute the cost inside the function. Do not change the function name or function parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, n):\n",
    "    # Write your code in place of None. Cost can be calculated using a single line of code.\n",
    "    # Remember w is a vector here.\n",
    "    \n",
    "    # TODO - Write the cost function - 10 points\n",
    "    cost = ( (1/(2*n))*np.sum((y - np.dot(x,w))**2) )\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead, ensure that the code you have written to compute the cost is correct. Just run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296.0734584980237\n"
     ]
    }
   ],
   "source": [
    "w_testcase=np.zeros((5,1))\n",
    "cost_verify= compute_cost(x, y, w_testcase, n)\n",
    "print(cost_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should be equal to 296.073458498. If it's equal to this, then move ahead. Else, re-check your code and re-verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "Write the code to perform gradient descent in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x , y , learning_rate , w , n , num_iters):\n",
    "    # In place of None, write the updated value of w0 in temp0 and of w1 in temp1\n",
    "    # TODO - Finish the gradient descent function - 10 points\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # derivative vector is given by : X_train.Transpose *  (( X_train * w)- y ) \n",
    "        temp =  None\n",
    "        w = None\n",
    "       \n",
    "\n",
    "        if(i%100==0):\n",
    "            # In place of None, call the cost you just coded above\n",
    "            cost= None\n",
    "            print(\"Cost\")\n",
    "            print(cost)\n",
    "             \n",
    "    return w      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead, ensure that your code to update w is correct. Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_testcase=np.zeros((5,1))\n",
    "g=gradient_descent(x , y , 0.0049 , w_testcase , n , 100000)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last output should be: 7.46236374. If it matches your out, then your code is likely to be correct. Otherwise, re-check your code and re-verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating the Batch Gradient Descent Function \n",
    "\n",
    "Integrating the above function into a single function multiple_linear_reg_model_gda: This function uses gradient descent algorithm to minimize the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiple_linear_reg_model_gda(x , y , n , learning_rate , num_iters):\n",
    "    #initialize the values of parameter vector w. It should be a column vector of zeros of dimension(n,1)\n",
    "    # TODO - Complete the function - 15 points\n",
    "    w = None\n",
    "    \n",
    "    # Calculate the initial cost by calling the function you coded above.\n",
    "    initial_cost= None\n",
    "    print(\"Initial Cost\")\n",
    "    print(initial_cost)\n",
    "    \n",
    "    # Calculate the optimized value of gradients by calling the gradient_descent function coded above\n",
    "    \n",
    "    w = None\n",
    "    \n",
    "    # Calculate the cost with the optimized value of w0 and w1 by calling the cost function.\n",
    "    \n",
    "    final_cost = None\n",
    "    print(\"Final Cost\")\n",
    "    print(final_cost)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when you have coded multiple_linear_reg_model_gda function, you can call this function to find the optimized values of parameters w. Before calling the function, set the values of learning_rate and num_iters. You may have to call this function several number of times with different values of num_iters and learning_rate to find the optimal values of w. For some values of learning_rate, it may give an error as the values of cost may reach a very high value(infinity) due to overshooting as discussed in the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = None\n",
    "num_iters = None\n",
    "\n",
    "# In place of None, call the multiple_linear_reg_model_gda.\n",
    "w = None\n",
    "print(w)\n",
    "\n",
    "# The value of final cost should be 14.3470049896 or nearly this(depending on the values of learning_rate and num_itersations you choose.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Equation Method\n",
    "Now, we will be writing the code to find the values of parameters w for our multiple linear regression model. This can also be used to cross-check the optimal values of w we just found above using method above. These values should be same (or nearly same).\n",
    "Instead of writing the code for normal equation in one line, you can break this into 3 parts: First calculate q=inverse of (dot of (X.T,X)) (these are pseudo commands, use original numpy commands to calculate q). Then z= dot of ( X.T , y) and then w_vec= dot of (q,z). Here, w_vec is vector of dimension (5,1) having two values. Example w0=w_vec[0][0].\n",
    "\n",
    "Note : Do not append a column of ones in x because you have already done before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "# TODO - Write the normal equation method - 15 points\n",
    "\n",
    "q = None\n",
    "z = None\n",
    "w_vec = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of w you just got above should be approximately same as the ones you got using multiple_linear_reg_model_gda.\n",
    "This assignment ends here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
